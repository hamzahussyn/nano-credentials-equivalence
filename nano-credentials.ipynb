{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Year              Field  \\\n",
      "8       2011      Public Health   \n",
      "14      1977  Aerospace Studies   \n",
      "15      1977  Aerospace Studies   \n",
      "17      1978  Aerospace Studies   \n",
      "18      1978  Aerospace Studies   \n",
      "...      ...                ...   \n",
      "305662  1970            Biology   \n",
      "305663  1968            Zoology   \n",
      "305665  1969            Zoology   \n",
      "305667  1918        Agriculture   \n",
      "305668  1917        Agriculture   \n",
      "\n",
      "                                                     Name       Number  \\\n",
      "8         Statistical Analysis of Continuous Outcom- Data          145   \n",
      "14                          United Slates Air Force Today     1A-1B-1C   \n",
      "15                 The Developmental Qrowtti of Air Power  21A-21B-21C   \n",
      "17                     Introduction to Aerospace Studies             1   \n",
      "18                               The military Force Today            2   \n",
      "...                                                   ...          ...   \n",
      "305662    Introduction to the Science of Living Organisms      11A-11B   \n",
      "305663           Advanced Biology of Marine Invertebrates          257   \n",
      "305665  Seminar in Comparative Functional Biology of I...          227   \n",
      "305667                             Principles of Dairying          102   \n",
      "305668  Bacteriology of Milk, Sanitary Milk Production...          117   \n",
      "\n",
      "                            Area           GenArea  \\\n",
      "8                Health Sciences      Professional   \n",
      "14      Aeronautical Engineering       Engineering   \n",
      "15      Aeronautical Engineering       Engineering   \n",
      "17      Aeronautical Engineering       Engineering   \n",
      "18      Aeronautical Engineering       Engineering   \n",
      "...                          ...               ...   \n",
      "305662                   Biology  Natural Sciences   \n",
      "305663                   Biology  Natural Sciences   \n",
      "305665                   Biology  Natural Sciences   \n",
      "305667               Agriculture      Professional   \n",
      "305668               Agriculture      Professional   \n",
      "\n",
      "                                              Description  Profs1  Profs2  \\\n",
      "8        (4) Three hours of lecture and two hours of l...     NaN     NaN   \n",
      "14       (22-2) One hour of lecture per week. This cou...     NaN     NaN   \n",
      "15       (2-2-2) One hour of lecture per week. This co...     NaN     NaN   \n",
      "17       (1) One hour lecture/ discussion per week. An...     NaN     NaN   \n",
      "18       One hour lecture/ discussion per week. An inv...     NaN     NaN   \n",
      "...                                                   ...     ...     ...   \n",
      "305662   (4-4) Three 1-hour lectures, one 3-hour labor...  9950.0  9951.0   \n",
      "305663   (5) (Formerlynumbered295 B) Full-time study a...  9951.0  9953.0   \n",
      "305665      (2) One 2-hour meeting per week. Pr Smith (F)   593.0  9954.0   \n",
      "305667   (Ro ADHOii SE) The secretion of milk, nature ...   549.0   997.0   \n",
      "305668   The production and distribution of the variou...   547.0   997.0   \n",
      "\n",
      "         Fall  Winter  Spring  Summer  Taught  \n",
      "8       False   False    True   False    True  \n",
      "14       True    True    True   False    True  \n",
      "15       True    True    True   False    True  \n",
      "17       True   False   False   False    True  \n",
      "18      False   False    True   False    True  \n",
      "...       ...     ...     ...     ...     ...  \n",
      "305662   True    True    True   False    True  \n",
      "305663  False   False    True    True    True  \n",
      "305665   True   False   False   False    True  \n",
      "305667   True   False   False   False    True  \n",
      "305668   True   False   False   False    True  \n",
      "\n",
      "[52275 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas.core.series import Series\n",
    "\n",
    "data_frame: DataFrame = pd.read_csv(r'./Courses_Berkeley_2018-01-15.csv', encoding='latin1')\n",
    "\n",
    "#Unique Courses\n",
    "data_frame = data_frame.drop_duplicates(subset=['Name'], keep='last')\n",
    "\n",
    "#Description is null\n",
    "data_frame = data_frame.dropna(subset=[\"Description\"])\n",
    "\n",
    "#Description too short\n",
    "data_frame = data_frame[data_frame['Description'].map(len) > 20]\n",
    "\n",
    "\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "lemmatizer: WordNetLemmatizer = WordNetLemmatizer()\n",
    "stemmer : PorterStemmer = PorterStemmer()\n",
    "sw_nltk = set(stopwords.words(\"english\"))\n",
    "\n",
    "descriptions: Series = data_frame['Description']\n",
    "\n",
    "\n",
    "custom_stop_words: set = (\"part\", \"class\", \"course\", \"one\", \"two\", \"three\", \"four\", \"discussion\", \"lecture\", \"hour\", \"day\",\"month\",\"semester\",\"week\",\"sophomore\",\"junior\",\n",
    "\"senior\",\"fresh\",\"seminar\",\"exam\",\"required\",\"summer\",\"winter\",\"student\",\"pre\",\"requisite\",\"prerequisite\",\"lecture\",\"introduction\",\"introduces\",\"essay\",\"notes\",\"textbook\",\n",
    "\"etc\",\"covering\",\"sp\",\"credit\",\"pr\",\"fsp\",\"info\",\"session\",\"read\",\"basic\",\"hard\",\"emphasis\",\"form\",\"primary\",\"understand\",\"learn\",\"discus\",\"learning\",\"general\",\"concept\",\"study\",\n",
    "\"overciew\",\"focus\",\"emphasize\",\"presented\",\"learning\",\"seminar\",\"proseminar\",\"topic\",\"major\",\"year\",\"distinguished\", \"presentation\",\n",
    "\"hour\", \"concept\",\"hours\", \"per\", \"week\", \"weeks\",\"year\", \"years\", \"month\", \"day\", \"days\", \"definition\", \"define\", \"elaborate\", \"fwsp\")\n",
    "\n",
    "stopwords_removed_description: list = []\n",
    "\n",
    "i = 0\n",
    "    \n",
    "for index, value in descriptions.iteritems():\n",
    "    text = str(value).lower()\n",
    "    text = re.sub('(\\\\d|\\\\W)+',' ',text)\n",
    "    text = re.sub('[\\(\\)]', ' ', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if not word in sw_nltk]\n",
    "    text = [word for word in text if not word in custom_stop_words]\n",
    "    \n",
    "    nouns_text:list = []\n",
    "    for word, pos in nltk.pos_tag(text):\n",
    "        if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "            nouns_text.append(word)\n",
    "    \n",
    "    text = nouns_text\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    #text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    stopwords_removed_description.append((' ').join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52275\n"
     ]
    }
   ],
   "source": [
    "#Verifying the length of output\n",
    "print(len(stopwords_removed_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laboratory regression model outcome data square property coefficient prediction model model assumption transformation outlier point variable interaction si covariance correlation correlation method com analysis variance facto model test assumption comparison effect model health component measure model', 'defines role structure category force air force dynamic instrumentofnationalpower camacho', 'trace air power concept application identifies change evolution seek impact development air superiority concept', 'air force rotc program survey state air preview study course cadet commission force comacho f', 'investigation structure state air force structure air force organization malor command']\n",
      "(52275, 55049)\n"
     ]
    }
   ],
   "source": [
    "# BoW -> Bag Of Words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(stopwords_removed_description)\n",
    "\n",
    "vectorized_descriptions = vectorizer.transform(stopwords_removed_description)\n",
    "\n",
    "print(vectorized_descriptions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "(52275,)\n",
      "34\n",
      "52275\n",
      "(52275, 90)\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "labels = data_frame['Area'].values\n",
    "\n",
    "labelencoder.fit(labels)    \n",
    "\n",
    "encoded_labels = labelencoder.transform(labels)\n",
    "\n",
    "categorical_labels = tf.keras.utils.to_categorical(encoded_labels)\n",
    "\n",
    "print(len(data_frame['Area'].unique()))\n",
    "print(encoded_labels.shape)\n",
    "print(encoded_labels[120])\n",
    "print(len(categorical_labels))\n",
    "print(categorical_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 90)                4954500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 120)               10920     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               14520     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 90)                10890     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,990,830\n",
      "Trainable params: 4,990,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = vectorized_descriptions.shape[1]  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(90, input_dim = input_dim, activation='relu'))\n",
    "model.add(layers.Dense(120, activation='relu'))\n",
    "model.add(layers.Dense(120, activation='relu'))\n",
    "model.add(layers.Dense(90, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "# import scikeras\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=100, batch_size=5000, verbose=0)\n",
    "\n",
    "history = model.fit(vectorized_descriptions,\n",
    "                    categorical_labels, \n",
    "                    epochs=200, \n",
    "                    verbose=False, \n",
    "                    batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.1486382782459259\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(vectorized_descriptions, categorical_labels, verbose=False)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept exploitation technique computer security security hacker permission attempt system system link way security flaw relies combination expansion knowledge practice issue client industry regulation threat target organization security presence point risk\n"
     ]
    }
   ],
   "source": [
    "test_case_one = 'This course will provide a basic understanding of computing, networking, programming concepts, and exploitation techniques, as they relate to computer security. In security testing, an ethical hacker with legal permission attempts to penetrate a system or systems to find a weak link and then analyze ways to correct the security flaws. Ethical hacking relies on a combination of creativeness, expansion of knowledge based on best practices, legal issues, and client industry regulations as well as known threats and the breath of the target. organization’s security presence or point of risk.'\n",
    "text = str(test_case_one).lower()\n",
    "text = re.sub('(\\\\d|\\\\W)+',' ',text)\n",
    "text = re.sub('[\\(\\)]', ' ', text)\n",
    "text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "text = word_tokenize(text)\n",
    "text = [word for word in text if not word in sw_nltk]\n",
    "text = [word for word in text if not word in custom_stop_words]\n",
    "    \n",
    "nouns_text:list = []\n",
    "for word, pos in nltk.pos_tag(text):\n",
    "    if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "        nouns_text.append(word)\n",
    "    \n",
    "text = nouns_text\n",
    "text = [lemmatizer.lemmatize(word) for word in text]\n",
    "text = (' ').join(text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 55049)\n"
     ]
    }
   ],
   "source": [
    "text_array = []\n",
    "text_array.append(text)\n",
    "\n",
    "vectorized_test_case = vectorizer.transform(text_array)\n",
    "print(vectorized_test_case.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.47212551e-17 6.10463463e-31 3.61998394e-30 1.48730368e-25\n",
      "  0.00000000e+00 1.73652913e-23 0.00000000e+00 3.30881236e-27\n",
      "  7.99098671e-20 7.60956299e-28 3.66748445e-27 1.52443412e-32\n",
      "  4.86283056e-07 1.43012071e-37 6.00445866e-34 1.47147653e-29\n",
      "  1.71510140e-29 5.61318665e-21 6.13609713e-19 9.99993443e-01\n",
      "  6.83299679e-19 2.37833197e-14 3.09668847e-24 0.00000000e+00\n",
      "  3.92366261e-13 3.45533877e-08 1.10550044e-13 8.85970342e-20\n",
      "  3.20280320e-28 5.61198893e-28 1.59985120e-30 0.00000000e+00\n",
      "  4.34533129e-30 1.81253501e-25 1.73473857e-11 1.02405655e-20\n",
      "  2.47398885e-37 3.18994831e-15 0.00000000e+00 2.70917500e-30\n",
      "  0.00000000e+00 1.02378619e-14 3.05450385e-06 0.00000000e+00\n",
      "  2.98301064e-26 2.50728740e-16 1.47635636e-11 1.09129630e-28\n",
      "  5.03199652e-12 3.84629070e-35 6.22148600e-13 0.00000000e+00\n",
      "  1.43239823e-36 1.22512852e-23 3.00956958e-06 3.74041171e-08\n",
      "  3.55367162e-27 3.96294952e-15 1.18833903e-27 2.19415090e-21\n",
      "  4.65983442e-37 9.85964247e-29 4.36354689e-18 1.96653164e-21\n",
      "  0.00000000e+00 7.71969777e-29 5.44519709e-22 1.33146131e-26\n",
      "  5.36245177e-23 6.93425640e-17 1.03239304e-17 3.43384528e-32\n",
      "  2.28099601e-31 1.00663152e-12 7.18472077e-35 1.27399286e-34\n",
      "  1.29200206e-10 6.08420866e-28 1.71889693e-18 1.73914905e-14\n",
      "  3.25884738e-32 2.42527092e-12 3.02090750e-23 4.97497613e-38\n",
      "  1.63059342e-34 1.02113578e-33 5.64681155e-31 8.38211897e-28\n",
      "  2.27813170e-34 0.00000000e+00]]\n",
      "[19]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n",
      "Computer Science\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_class = model.predict(vectorized_test_case) \n",
    "classes_x = np.argmax(predicted_class,axis=1)\n",
    "\n",
    "print(predicted_class)\n",
    "print(classes_x)\n",
    "print((model.predict(vectorized_test_case) > 0.5).astype(\"int32\"))\n",
    "\n",
    "# print(labels[39])\n",
    "# print(data_frame['Description'].values[39])\n",
    "\n",
    "for i in range(len(encoded_labels)):\n",
    "    if encoded_labels[i] == classes_x[0]:\n",
    "        print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10142\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(encoded_labels)):\n",
    "    if(encoded_labels[i] == predicted_class[0][0]):\n",
    "        print(f\"{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22 units from Group II (aslistedherein) including: German 100 (3), 101 (2), 102 (2), 103 (3), 104 (3), 112 (3) and six units taken from literature courses;\n"
     ]
    }
   ],
   "source": [
    "print(data_frame[\"Name\"].values[10142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4cebde5dfe8ab5824187f89ac3d43a9c01ffdc72550417062638a9eeab7ee54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
